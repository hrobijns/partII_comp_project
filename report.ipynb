{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <u> **The Naïve, Barnes-Hut, and Fast Multipole Methods**  </u>\n",
    "### *Implementation, Analysis, and Evaluation of different Algorithms for $N$-Body Simulations*  \n",
    "\n",
    "**Author:** Hugo Robijns\n",
    "\n",
    "**Date:** April 2025 \n",
    "\n",
    "**Abstract:**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is written similarly to a typical formal write-up, and does not contain the bulk of the code, all of which can be found in the attached repository (see the README.md file for a detailed breakdown on the structure of the repository). Plots and tables are pre-generated since generating them on the spot would cause the notebook to run too slowly (N-body simulation is notoriously expensive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction:**\n",
    "The analysis of many-body systems is highly relevant to many fields, from celestial bodies interracting gravitationally, to vortex methods in computational fluid dynamics, and more [CITE]. These systems are complex to simulate: for three or more bodies the system becomes chaotic and extremely difficult to approach analytically without major simplifications, and naïvely calculating pairwise interractions for $N$ bodies leads to a numerical complexity of $\\mathcal{O}(N^2)$, which scales poorly.  \n",
    "\n",
    "&emsp; &emsp; This report aims to analyse and implement two algorithms which attempt to reduce this complexity, the Barnes-Hut and fast multipole method (FMM) techniques, alongside the brute-force $\\mathcal{O}(N^2)$ approach, in order to compare their performances. For the sake of comparison, we will mainly base analysis around the simple 2D example of particles under the influence of a logarithmic Coulombic potential, sometimes referred to as a Coulomb gas.\n",
    "\n",
    "&emsp; &emsp; The report begins with a section analysing the algorithms and their complexity, followed by a section describing their implementation, and finally a discussion section. We find that: \n",
    "\n",
    "&emsp; &emsp; All accompanying code is found in this repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/simulation.gif\" width=\"99%\" alt=\"figures/quadtree_plot.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure 1: A simulation of a 2D Coulombic gas consisting of 1000 particles, with positively charged particles coloured red and negatively charged particles coloured blue._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **1. Analysis of Algorithms**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *1.1 Naïve Pairwise Calculation, $\\mathcal{O}(N^2)$*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a 2D system, a particle $i$ of charge $q_i$ situated at $\\vec{x}_i = (x_i,y_i)$ produces a electrostatic potential $\\phi_{i}(x,y)$ and field $E_{i}(x,y)$ given by:\n",
    "$$\\phi_{i}(x,y) = -kq_i\\log(|\\vec{x}-\\vec{x}_i|)$$\n",
    "$$E_{i}(x,y) = -\\nabla_{2\\text{D}}\\phi_{x_0}(x,y) = kq_i\\frac{(\\vec{x}-\\vec{x}_i)}{|\\vec{x}-\\vec{x}_i|^2}$$\n",
    "&emsp; &emsp; where $k$ is a constant. Therefore for an $N$-body system, we must sum over the fields produced by all the other particles, and the equations of motion become:\n",
    "$$m_i \\frac{\\text{d}^2\\vec{x}_i}{\\text{d}t^2}  = q_i \\sum_{j=1, j\\neq i}^{N} \\frac{q_j (\\vec{x}_j-\\vec{x}_i)}{|(\\vec{x}_j-\\vec{x}_i)|^2}$$ \n",
    "\n",
    "&emsp; &emsp; from which the position and velocity of the particles can be updated through integration.\n",
    "\n",
    "It is clear to see that in order to simulate such a system directly, we must carry out $N-1$ calculations for each of the $N$ particles (or half of the particles, if exploiting the symmetry of Newton's $3^\\text{rd}$ law), leading to a theoretical complexity of $\\mathcal{O}(N^2)$. Note also that the force between two particles diverges as they get close to each other: this requires the inclusion of a softening parameter $\\epsilon$ which will be discussed further in Section 2.1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *1.2 Barnes-Hut Algorithm, $\\mathcal{O}(N\\log N)$*  \n",
    "The Barnes-Hut Algorithm, introduced by Josh Barnes and Piet Hut in 1986 [CITE] attempts to reduce complexity by treating distant clusters of particles as a single body. It does this through hierarchical decomposition, in this case the use of tree data structures, specifically a quadtree in 2D. \n",
    "\n",
    "##### 1.2.1 Tree Construction\n",
    "Beginning with a topmost node that represents the whole simulation space, a quadtree is formed by subdividing the space into 4 quadrants recursively until each body lies in its own leaf node, a node with no children (see Figure 2). Each node, both internal and leaf nodes, contains information about the charge distribution (specifically the total charge and centre of charge) of the node. Formally, they are constructed by inserting particles into the data structure one after the other:\n",
    "\n",
    "1. if the node into which the particle is being placed is an empty leaf node, the particle is simply placed there and the total charge and centre of charge position of the node are trivially updated.\n",
    "\n",
    "2. if the node is an internal node (i.e. a node with children), the total charge and centre of charge position of the node are updated, and we attempt to put the particle into the appropriate child.\n",
    "\n",
    "3. if the node is a leaf node which already contains a particle, the total charge and centre of charge position of the node is updated, and the node is subdivided into 4 quadrants. Then, both particles are placed into their appropriate quadrants as above, which may require further subdivision if they end up in the same quadrant again.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/quadtree_plot.png\" width=\"99%\" alt=\"figures/quadtree_plot.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure 2: A visualisation of the quadtree constructed for 10 particles in a 2D simulation. The square grid-lines seen in the left plot are the spatial borders of the leaf nodes, the smallest subdivisions of the tree which have no children of themselves, and therefore contain either 0 or 1 particles. The figure on the right shows a schematic of the quadtree: hollow markers indicate empty nodes, and solid markers indicate nodes containing particles._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.2 Force Calculation\n",
    "To calculate forces, the tree is recursively traversed from the root for each particle:\n",
    "\n",
    "1. If the node is a leaf node and contains a particle that is not itself, then the force is calculated in the usual way.\n",
    "\n",
    "2. If the node is an internal node, the ratio: $$\\frac{\\text{size of node in space (i.e. side length of the cube)}}{\\text{distance from particle to centre of charge of node}} \\equiv \\frac{s}{d} $$ is calculated. If this is less than a threshold value $\\theta$ (usually taken to be $\\sim$ 1), then the node is seen to contain particles that are closely packed and far away, and as a result can be treated as one single particle, ignoring its children nodes. The force on the particle is calculated in the usual way, using the centre of charge position and total charge of the node.\n",
    "\n",
    "3. If $s/d > \\theta$, the process recursively continues for each of the children of the node, until reaching the leaf node or a node which satisfies the above condition.\n",
    "\n",
    "These forces are then summed to give an overall acceleration for the particle. It is clear to see that $\\theta$ determines the accuracy of the simulation: a larger $\\theta$ leads to fewer calculations but a more approximate solution, whilst a smaller $\\theta$ may take longer but provide a more reliable solution. In the limit $\\theta\\rightarrow0$ the algorithm reduces to the brute-force approach, since no clusters are grouped together.\n",
    "\n",
    "##### 1.2.3 Complexity\n",
    "For a _balanced_ quadtree with $h$ levels, the bottom level has $4^h$ nodes. Therefore:\n",
    "$$ 4^h \\geq N \\Rightarrow h \\sim \\log_4 N = \\frac{\\log_2 N}{\\log_2 4} = \\frac{1}{2} \\log_2 N \\text{ or } \\mathcal{O}(\\log N)$$\n",
    "Insertion of each of the $N$ particles requires travelling the $h$ levels of the tree from root to leaf, therefore the overall complexity of constructing a quadtree is given by $\\mathcal{O}(N\\log N)$. \n",
    "\n",
    "The complexity of the force calculation step is more complicated. A typical reasoning (as laid out in the original paper) follows as such: again assuming a balanced quadtree (i.e. homogoneously distributed charge), consider quadrupling the number of particles. This is equivalent to adjoining 3 root nodes to the existing one. To calculate the force on a particle situated in the 'original tree', these additional particles will contribute a fixed number of extra calculations, which is a function of $\\theta$ but not $N$. To imagine this, consider $\\theta \\gg 1$: this will simply add 3 force calculations, since the centre of charge of all three of the the 'additional root nodes' are far enough away, and they can be treated as a single particle. Reducing $\\theta$ to more reasonable values will increase the number of children of these 'additional nodes' that need to be explored, but assuming $N$ is large enough (and this further exploration is therefore not reaching leaf nodes), then the number of additional calculations does not depend on $N$. Since the number of force calculations is increasing by an additive constant (a function of $\\theta$) whilst $N$ is increasing by a multiplicative factor, the complexity goes as $\\mathcal{O}(\\log N)$ for a single particle, or $\\mathcal{O}(N\\log N)$ for $N$ particles. \n",
    "\n",
    "Summing the tree construction and force calculation complexities leads to overall complexity $\\mathcal{O}(N\\log N)$, a major improvement on the naive $\\mathcal{O}(N^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### *1.3 Fast Multipole Method (FMM), $\\mathcal{O}(N)$* \n",
    "The FMM algorithm was introduced by Leslie Greengard and Vladimir Rokhlin Jr. in the 1980s [CITE]. It uses similar hierarchical decomposition methods as the Barnes-Hut algorithm, but instead works with more accurate local and multipole expansions of the potential rather than simple information on the centre of charge of a node. Re-use of computation by traversing the tree in both directions allows complexity to be reduced to $\\mathcal{O}(N)$ for arbitrary precision. For the sake of this report, detailed derivation of the maths and convergence properties will not be carried out: see the original paper for more detailed discussion. \n",
    "\n",
    "A high-level overview of the algorithm is as follows:\n",
    "\n",
    "1. A quadtree is constructed as in the Barnes-Hut method, however the approach need not be as rigorous, since the algorithm simply requires leaf nodes to house a small, constant ($\\mathcal{O}(1)$) number of bodies.\n",
    "\n",
    "2. The tree is traversed from bottom to top, calculating the multipole expansion for the potential produced by each node at a point far away.\n",
    "\n",
    "3. The tree is traversed from top to bottom, calculating the local expansion, or the potential felt at each node due to other nodes far away.\n",
    "\n",
    "4. At the bottom 'leaf' level, direct pair-wise interractions are calculated with nearest neigbours - since in step 1. we ensured each leaf node had a small number of bodies, this is inexpensive.\n",
    "\n",
    "##### 1.3.1 Multipole Expansions and Translations\n",
    "For $k=1$, expressing the logarithmic potential from before produced by a particle $i$ in terms of complex variables $(x,y) \\in \\mathcal{R}^2 \\rightarrow z = x+iy \\in \\mathcal{C}$, we get:\n",
    "$$\\phi_{i}(x,y) \\rightarrow \\phi_{i}(z) = \\text{Re}(-\\log(z-z_0))$$\n",
    "&emsp; &emsp; which for $|z|>|z_0|$ (and absorbing the minus sign into $q$) can be expanded as:\n",
    "$$ \\phi_{i}(z) = q \\left(\\log(z) - \\sum_{k=1}^\\infty \\frac{1}{k} \\left( \\frac{z_0}{z} \\right)^k \\right) $$\n",
    "Putting together the potential, as expressed above, from $N$ particles of charge $\\{q_i, i = 1 \\ldots N\\}$ at positions $\\{z_i, i = 1 \\ldots N\\}$, gives us the _multipole expansion_:\n",
    "$$\\phi(z) = Q\\log(z) + \\sum_{k=1}^\\infty \\frac{a_k}{z^k} \\phantom{xxx}\\text{ where } Q = \\sum_{i=1}^{N} q_i \\text{ and } a_k = \\sum_{i=1}^{N}\\frac{-q_iz_i^k}{k}$$\n",
    "The efficiency in the FMM algorithm comes in part due to its re-use of computation of the above expansion, through the use of translations. These allow expansion coefficients for adjacent level nodes to be calculated more cheaply. The three relevant translations are the multipole-to-multipole shift (M2M translation):\n",
    "$$ \\phi(z) = Q \\log (z) + \\sum_{l=1}^\\infty \\frac{b^l}{z}  \\phantom{xxx}\\text{ where } b_l = \\sum_{k=1}^l a_k z_0^{l-k} \\binom{l-1}{k-1} -\\frac{a_0 z_0^l}{l} $$\n",
    "&emsp; &emsp; the multipole-to-local shift (M2L translation):\n",
    "$$ \\phi(z) = \\sum_{l=0}^{\\infty}b_l z^l  \\phantom{xxx}\\text{ where } b_0 = \\sum_{k=1}^\\infty (-1)^k \\frac{a_k}{z_0^k} + a_0 \\log(-z_0) \\text{ and } b_l = \\frac{1}{z_0^l} \\sum_{k=1}^\\infty \\frac{(-1)^k a_k}{z_0^k}\\binom{l+k-1}{k-1} - \\frac{a_0}{lz_0^l}$$\n",
    "&emsp; &emsp; and the local-to-local shift (L2L translation):\n",
    "$$ \\sum_{k=0}^N a_k(z-z_0)^k = \\sum_{l=0}^N \\left(\\sum_{k=l}^N a_k \\binom{k}{l} (-z_0)^{k-l} \\right)z^l$$\n",
    "\n",
    "\n",
    "##### 1.3.2 Algorithm and Complexity\n",
    "Starting from the leaf nodes, the multipole expansion for each node is calculated using the above analytical expression. Since we are essentially aggregating (summing) over the charges, this step is $\\mathcal{O}(N)$. Going up the tree, the expansion of each node can be formed through aggregating the expansion of its children, using the M2M translation and summing. Again, since this is simply an aggregation over the charges, the whole upwards pass is $\\mathcal{O}(N)$.\n",
    "\n",
    "Working downards from the top of the tree, we calculate the local (Taylor) expansion of the potential experienced at each node. Firstly, the local expansion of the parent node (if it exists) is shifted to the centre of the new node using an L2L translation. Then, the multipole expansion of non-adjacent (far away) nodes is translated into a local expansion at the location of the node, using M2L translation. In 2D, this can only ever be less than 27 interactions, independent of $N$, (see Figure X) and therefore is a constant amount of work. Finally, upon reaching the bottom leaf level, we calculate the direct contributions from the few remaining bodies, which is not computationally expensive since there are a small number of bodies at this level. Overall, the work done in the downard pass is constant for each body, and thefore $\\mathcal{O}(N)$ overall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/FMMinteractionlist.png\" width=\"99%\" alt=\"figures/FMMinteractionlist.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure 3: A demonstration of how the interaction list is determined for a specific node (green) in FMM. At each level, non-adjacent (purple) nodes are treated using M2L translations. Of the nodes that are too close (red), further division occurs (moving down a level in the tree) and the process repeats itself. Those that have already been dealt with (grey) are naturally passed down through the L2L translations from parents to kids. At the bottom level, the potentials from the remaining particles are summed naively, since there are only a small number left. Looking at levels 3 and 4, it is clear to see that in 2D, the interaction set is at most 27 (6x6 - 3x3), and therefore provides a constant amount of work, independant of $N$._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "With an efficient quadtree implementation, this thereotically allows N-body simulation which is linear in N, a huge improvement on the quadratic naïve approach.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Implementation and Performance**\n",
    "\n",
    "All three algorithms were implemented in vanilla Python alongside some basic open-source libraries, mainly _Numpy_ and _Matplotlib_, and modules _time_ and _collections_. For timing comparison, the results in this report were produced by running the algorithms on a Macbook Air with CPU 1.1 GHz Quad-Core Intel Core i5. Note that, since the aim of the report was to compare performance and complexities, all simulations were carried out with arbitrary simulation units (Coulomb constant $k=1$, $q=1$ etc.). The README.md file gives information on where to find the relevant scripts, which are extensively commented. This section provides an overview of certain implementation choices that were made, as well as tests which show that the algorithms were implemented correctly.\n",
    "\n",
    "### *2.1 Naïve Pairwise Calculation (source/naive)*\n",
    "The brute force implementation is found in source/naive. This algorithm is the simplest to implement, but its time complexity scales the worst with $N$. The following subsections discuss the softening parameter, time step and integration techniques, which are relevant for the other algorithms too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 2.1.1 Softening Parameter ($\\epsilon$) and Time Step ($\\Delta t$)\n",
    "In order to avoid divergence and instability when particles become close, we introduce a softening parameter $\\epsilon$ such that:\n",
    "$$\\phi_{i}(x,y)=-kq_i\\log(|\\vec{x}-\\vec{x}_i|)\\phantom{x}\\xrightarrow{\\text{softening}} \\phantom{x}\\phi_{i}(x,y)=-kq_i\\log(\\sqrt{|\\vec{x}-\\vec{x}_i|^2 + \\epsilon^2})$$ \n",
    "$$E_{i}(x,y) = -\\nabla_{2\\text{D}}\\phi_{x_0}(x,y) = kq_i\\frac{(\\vec{x}-\\vec{x}_i)}{|\\vec{x}-\\vec{x}_i|^2}\\phantom{x}\\xrightarrow{\\text{softening}}\\phantom{x} E_{i}(x,y)  = kq_i\\frac{(\\vec{x}-\\vec{x}_i)}{|\\vec{x}-\\vec{x}_i|^2+\\epsilon^2}$$\n",
    "$\\epsilon$ should be chosen to be small enough to keep the simulation accurate, but large enough to avoid singularities. This depends on the scale of the system, and the time-step, $\\Delta t$. A demonstration of the influence of $\\epsilon$ is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/softening.gif\" width=\"99%\" alt=\"figures/FMMinteractionlist.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure 4: a demonstration of the effect of the softening parameter $\\epsilon$ showing an animation of three bodies interracting (left), and the percentage total energy change of the system from its initial value for three different values of $\\epsilon$ (right). For smaller values of $\\epsilon$, the close passes cause larger variations away from the initial, conserved energy of the system. However, for larger values of $\\epsilon$, this level of conserved energy is further away from the reality. Note that for this simulation, in contrast to the others in this report, an attractive potential has been used to encourage close passes._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work has been carried out in order to quantify the most reliable size of $\\epsilon$ and $\\Delta t$ for a system, often based on how far particles travel in a time-step in relation to their proximity [CITE]. Indeed, a good way forward is to use an adapative $\\Delta t$, which can become smaller as bodies become closer to each other, in order to accurately and stably explore regions of high accelaration. Since this project is less about dealing with collisions, and more about analysing the complexities and performances of the algorithms in scaling to large numbers of bodies, a simple comparison and tuning process was carried out, settling on constant values $\\epsilon \\sim 0.5$, and $\\Delta t \\sim 0.01$. These values were kept consistent and used for the other two algorithms as well. In addition, for our complexity analysis we consider systems wherein the particles are well-separated, to avoid any unnecessary instability.\n",
    "\n",
    "\n",
    "##### 2.1.2 Integration Techniques\n",
    "Upon calculating the individual acceleration each particle experiences, we integrate to find their updated velocity and position. There are many different possible integration techniques, but we used the symplectic 'kick-drift-kick' technique due to its easy implementation and improved energy conservation compared to the simple Euler step. It is a form of Verlet-velocity integration, and can be implemented through the following equations:\n",
    "\n",
    "\n",
    "1. $x(t+\\Delta t) =x(t)+v(t)\\Delta t+\\frac{1}{2}a(t)(\\Delta t)^2$\n",
    "\n",
    "2. calculate $a(t+\\Delta t)$\n",
    "\n",
    "3. $v(t+\\Delta t) = v(t) + \\frac{1}{2}\\left(v(t)+v(t+\\Delta t)\\right)\\Delta t$\n",
    "\n",
    "&emsp; &emsp; where $x$ is position, $v$ is velocity, $a$ is acceleration, and $t$ is time. The figure below shows the energy drift over time for a simple Euler step compared to 'kick-drift-kick'. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/integration.gif\" width=\"99%\" alt=\"figures/FMMinteractionlist.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure 5: A plot showing an animation of 75 bodies under a repulsive potential (left) and the associated energy conservation of the system (right) for two different integrators, Euler step and kick-drift-kick. As expected, kick-drift-kick conserves energy better than Euler. The error in an Euler step approach is theoretically linear over time: the tailing off seen is most likely due to acceleration (and therefore distance travelled each step, and associated energy drift) reducing as particles spread further apart over time._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 2.1.2 Computation Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/naivecomplexity.png\" width=\"99%\" alt=\"figures/naivecomplexity.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure 6: A plot showing time taken to compute a single step, averaged over 5 seeds (left) and the equivalent data tabulated, along with peak memory usage, for selected values of N (right). As expected, the naïve approach scales poorly with $N$, and the plot is (loosely) quadtratic. The 'wobbles' and spread are most-likely caused by cache-level effects and python interpreter overheads: once this approach was vectorised, a much smoother quadratic was observed (see Section X)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2.2 Barnes-Hut (source/BH)*\n",
    "The Barnes-Hut implementation is found in source/BH. The main difference compared with the naïve approach is the introduction of the quadtree for hierarchical decomposition: softening, force calculations (albeit different ones) and integration proceeds identically to before. \n",
    "\n",
    "##### 2.2.1 Quadtree\n",
    "\n",
    "\n",
    "##### 2.2.1 Theta\n",
    "A good verification to ensure the implementation is working correctly is observing how the model behaves as a function of $\\theta$. We expect that reducing $\\theta$ brings the model closer to the naïve approach, improving energy conservation, but also increasing computation time. These effects are shown in Figure X below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "  <img src=\"figures/theta_energy.png\" width=\"49%\" alt=\"theta_energy.png\" />\n",
    "  <img src=\"figures/theta_time.png\" width=\"49%\" alt=\"other_figure.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure 7: two plots showing energy conservation over time for different values of $\\theta$ (left) and computation time - for a single step of 200 bodies - against $\\theta$ (right). As expected, increasing $\\theta$ leads to a (small) worsening of energy conservation, but also a reduction of computing time, and vice versa._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1 Complexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/BHcomplexity.png\" width=\"99%\" alt=\"figures/BHcomplexity.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure 8: A plot showing, for $\\theta =0.5$, time taken to compute a single step, averaged over 5 seeds (left) and the equivalent data tabulated, along with peak memory usage, for selected values of N (right). As expected, the BH approach scales considerably better than the naive approach, but uses more memory due to the more complicated data structures used._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2.1 FMM (source/FMM)*\n",
    "The FMM implementation is found in source/FMM. This algorithm is by far the most complex to implement and relies on both hierarchical decomposition (another quadtree), and careful manipulation of the various aforementioned expansions and translations during a double traversal of the tree. As mentioned in Section X, increasing expansion order should allow us to increase precision of the solution (theoretically until machine precision). Figure 9 shows relative error compared to the direct approach for increasing expansion order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "  <img src=\"figures/FMMerror.png\" width=\"52%\" alt=\"FMMerror.png\" />\n",
    "  <img src=\"figures/FMMtiming_p.png\" width=\"47%\" alt=\"FMMtiming_p.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/FMMcomplexity.png\" width=\"99%\" alt=\"figures/BHcomplexity.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Results and Discussion**\n",
    "\n",
    "### _3.1 Accuracy (conservation of energy, linear momentum and angular momentum)_\n",
    "\n",
    "### _3.2 Extensions and further work_\n",
    "##### 3.2.1 Different Problems and 3D\n",
    "##### 3.2.2 Vectorisation and parallelisation\n",
    "\n",
    "### _3.3 Complexities as a function of N_\n",
    "- showing number of calculations as a function of N\n",
    "- showing time and memory as a function of N\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography  \n",
    "\n",
    "1. J. Barnes and P. Hut, *A Hierarchical O(N log N) Force-Calculation Algorithm*, Nature, 1986.  \n",
    "2. L. Greengard and V. Rokhlin, *A Fast Algorithm for Particle Simulations*, Journal of Computational Physics, 1987.  \n",
    "3. D. J. Griffiths, *Introduction to Electrodynamics*, Cambridge University Press, 2017.  \n",
    "\n",
    "<a id='bibliography'></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
